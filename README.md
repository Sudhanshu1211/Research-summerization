
````markdown
# ğŸ§  GenAI Document Assistant

An intelligent AI backend built with **FastAPI** that reads, understands, and reasons through uploaded PDF or TXT documents. Designed to:
- Comprehend content
- Answer free-form questions
- Generate logic-based challenges
- Justify every response with references from the document

---

## ğŸ“ Project Structure

```bash
genai_backend/
â”œâ”€â”€ main.py                     # FastAPI entry point
â”œâ”€â”€ requirements.txt            # Project dependencies
â”œâ”€â”€ Dockerfile                  # Containerization config
â”œâ”€â”€ setup.py                    # Package metadata (optional)
â”œâ”€â”€ README.md                   # Project documentation
â”œâ”€â”€ params.yaml                 # Configurable model and pipeline parameters

â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py             # Global settings and API key config

â”œâ”€â”€ data/
â”‚   â””â”€â”€ uploads/                # Uploaded documents go here
â”‚       â””â”€â”€ .gitkeep

â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ .gitkeep            # Placeholder for CI/CD workflows

â”œâ”€â”€ api/
â”‚   â””â”€â”€ routes.py               # FastAPI route definitions (upload, ask, challenge)

â”œâ”€â”€ models/
â”‚   â””â”€â”€ schemas.py              # Pydantic request/response models

â”œâ”€â”€ research/
â”‚   â””â”€â”€ dev_trials.ipynb        # Prototyping and experimentation notebooks

â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚
â”‚   â”œâ”€â”€ components/             # Core logic modules
â”‚   â”‚   â”œâ”€â”€ document_service.py     # PDF/TXT parsing and cleaning
â”‚   â”‚   â”œâ”€â”€ summarizer.py           # Document summarization logic
â”‚   â”‚   â”œâ”€â”€ question_answering.py   # QA via retrieval-based LLM (Ask Anything)
â”‚   â”‚   â”œâ”€â”€ question_generation.py  # Logic-based question generator
â”‚   â”‚   â””â”€â”€ evaluation.py           # Answer evaluation + feedback logic
â”‚
â”‚   â”œâ”€â”€ pipeline/               # End-to-end orchestrators
â”‚   â”‚   â”œâ”€â”€ document_pipeline.py    # Upload â†’ Parse â†’ Chunk â†’ Embed
â”‚   â”‚   â””â”€â”€ interaction_pipeline.py # Manages Ask & Challenge user flow
â”‚
â”‚   â”œâ”€â”€ utils/                  # Common utility modules
â”‚   â”‚   â”œâ”€â”€ file_utils.py           # File reading, saving, and MIME handling
â”‚   â”‚   â”œâ”€â”€ chunk_utils.py          # Text splitting, cleaning, metadata tagging
â”‚   â”‚   â””â”€â”€ llm_utils.py            # Wrapper for LLM interaction and prompt control
â”‚
â”‚   â””â”€â”€ Agent/                  # LLM provider wrappers
â”‚       â”œâ”€â”€ openai_agent.py         # OpenAI GPT API abstraction
â”‚       â””â”€â”€ gemini_agent.py         # Gemini API abstraction
````

---

## ğŸš€ Features

* âœ… Upload PDF/TXT files
* âœ… Auto-summary in â‰¤150 words
* âœ… Ask Anything â€” free-form Q\&A with justifications
* âœ… Challenge Me â€” generates and evaluates logical questions
* âœ… Uses OpenAI or Gemini LLMs
* âœ… Clean modular backend architecture

---

## ğŸ›  Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/genai-document-assistant.git
cd genai-document-assistant
```

### 2. Create Virtual Environment

```bash
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

> âœ… Use the minimal `requirements.txt` below to avoid bloat:

```txt
fastapi>=0.103.0
uvicorn>=0.23.2
python-dotenv>=1.0.0
pydantic>=2.3.0
python-multipart>=0.0.6
openai
google-generativeai>=0.3.0
PyPDF2>=3.0.0
unstructured>=0.5.0
```

### 4. Set API Keys

Create a `.env` file or configure `config/settings.py`:

```python
OPENAI_API_KEY = "your-openai-api-key"
GEMINI_API_KEY = "your-gemini-api-key"
DOC_UPLOAD_DIR = "./data/uploads/"
```

### 5. Run the API Server

```bash
uvicorn main:app --reload
```

Then open your browser at: [http://localhost:8000/docs](http://localhost:8000/docs)

---

## ğŸ“¡ API Endpoints

| Route                     | Method | Description                           |
| ------------------------- | ------ | ------------------------------------- |
| `/upload`                 | POST   | Upload a document (PDF/TXT)           |
| `/summary/{session_id}`   | GET    | Retrieve the document summary         |
| `/ask`                    | POST   | Ask a contextual question             |
| `/challenge/{session_id}` | GET    | Get 3 logic-based questions           |
| `/evaluate`               | POST   | Evaluate answers against the document |

---

## ğŸ§± Component Breakdown

### ğŸ“ `src/components/`

Handles document parsing, summarization, question answering, challenge generation, and evaluation logic.

### ğŸ“ `src/pipeline/`

Coordinates multi-step workflows such as uploading, chunking, and inference.

### ğŸ“ `src/Agent/`

Abstracts LLM providers like OpenAI and Gemini â€” easily switchable via config.

### ğŸ“ `api/routes.py`

Contains all FastAPI endpoint routes.

### ğŸ“ `models/schemas.py`

Holds Pydantic request and response models for type-safe API interaction.

---

## ğŸ³ Docker Support (Optional)

### Build the Docker image

```bash
docker build -t genai-backend .
```

### Run the container

```bash
docker run -p 8000:8000 genai-backend
```

---

## ğŸ§ª Future Enhancements

* â³ LangChain memory/context support
* â³ Snippet highlighting for answers
* â³ MongoDB or vector DB for long-term memory
* â³ Role-based access control (user/admin)

---

## ğŸ‘¨â€ğŸ’» Author

Sudhanshu1211

---

## ğŸ“„ License

This project is licensed under the MIT License.



